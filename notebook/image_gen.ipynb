{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load biến môi trường từ .env\n",
    "load_dotenv()\n",
    "\n",
    "HF_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "client = InferenceClient(provider=\"hf-inference\", api_key=HF_API_KEY)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_grouped_texts(folder_path):\n",
    "    \"\"\"\n",
    "    Nhóm các file theo {group}_{number}.txt, sau đó tổng hợp nội dung từng nhóm.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Đường dẫn tới thư mục chứa các file .txt\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các văn bản tổng hợp của từng nhóm\n",
    "    \"\"\"\n",
    "    files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
    "    grouped_files = defaultdict(list)\n",
    "    \n",
    "    # Nhóm file theo group và sắp xếp theo số thứ tự\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "        parts = filename.rsplit(\"_\", 1)\n",
    "        if len(parts) == 2 and parts[1].endswith(\".txt\"):\n",
    "            group, number = parts[0], parts[1][:-4]  # Loại bỏ đuôi .txt\n",
    "            if number.isdigit():\n",
    "                grouped_files[group].append((int(number), file))\n",
    "    \n",
    "    # Đọc và ghép nội dung từng nhóm\n",
    "    merged_texts = []\n",
    "    for group in sorted(grouped_files.keys()):\n",
    "        grouped_files[group].sort()  # Sắp xếp theo số thứ tự\n",
    "        merged_content = \"\\n\".join(open(file, encoding=\"utf-8\").read() for _, file in grouped_files[group])\n",
    "        merged_texts.append(merged_content)\n",
    "    \n",
    "    return merged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(description):\n",
    "    \"\"\"\n",
    "    Nhận một đoạn văn mô tả chi tiết và trả về một câu mô tả cực ngắn gọn, chỉ nêu các yếu tố chính của hình ảnh.\n",
    "\n",
    "    Args:\n",
    "        description (str): Đoạn văn mô tả chi tiết.\n",
    "\n",
    "    Returns:\n",
    "        str: Một câu tóm tắt rất ngắn về hình ảnh.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là chuyên gia mô tả hình ảnh. Hãy đọc đoạn mô tả dưới đây và rút gọn thành một câu cực ngắn, chỉ giữ lại các yếu tố quan trọng nhất.\n",
    "\n",
    "    Đoạn mô tả:\n",
    "    {description}\n",
    "\n",
    "    Hãy trả về đúng một câu ngắn nhất bằng Tiếng Anh có thể nhưng vẫn đầy đủ ý chính.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi gọi API Gemini: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt, output_path):\n",
    "    image = client.text_to_image(prompt,model=\"stabilityai/stable-diffusion-3.5-large\")\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = \"../data/text\"\n",
    "merged_texts = merge_grouped_texts(text_folder)\n",
    "index = 0\n",
    "\n",
    "for merged_text in tqdm(merged_texts, desc=\"Processing\", unit=\"image\"):\n",
    "    output_path = f\"../data/image/{index}.png\"\n",
    "    prompt = describe_image(merged_text)\n",
    "    print(prompt)\n",
    "\n",
    "    # Cơ chế retry với backoff\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            generate_image(prompt, output_path)\n",
    "            time.sleep(60)  # Chờ sau khi tạo ảnh thành công\n",
    "            break  # Nếu thành công thì thoát khỏi vòng lặp retry\n",
    "        except HfHubHTTPError as e:\n",
    "            print(f\"Lỗi khi gọi API: {e}\")\n",
    "            retry_count += 1\n",
    "            wait_time = 2 ** retry_count + random.uniform(0, 1)  # Exponential backoff\n",
    "            print(f\"Thử lại sau {wait_time:.2f} giây...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
